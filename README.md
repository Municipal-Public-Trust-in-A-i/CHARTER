# CHARTER
MPTIA Charter

## INTRODUCTION

To ensure ALL public resources and benefits are widely accessible across all segments of society, our organization supports approaches to AI fundamentals, system development, and deployment. We recognize the importance of acceptance across diverse groups characterized by sociocultural identities, age, gender, health status, geography, income, and education. It is crucial to consider what individuals or groups find acceptable and how they evaluate trustworthiness during the design, evaluation, and deployment of technologies. Additionally, we emphasize the need to develop methods that guarantee fairness, fostering acceptance, trustworthiness, and the elimination of adverse biases, including social bias when implementing such methods.

In the realm of AI, including ML, there are significant challenges related to non-discrimination, due process, and explainability of decision-making. By explaining the inference processes of modern ML approaches and algorithms, we contribute to a better understanding of the mechanisms influencing fairness and trust in these algorithms. Furthermore, biases introduced by data sampling, data selection, algorithm design, and optimization criteria impact fairness. Therefore, we encourage research that advances the comprehension of these factors.

Our organization will support research across a broad range of topics that are in line with the overall objectives, encompassing but not limited to:

1. Incorporating fairness into the design of AI systems.
2. Enhancing transparency, explainability, inclusivity, and accountability in AI systems.
3. Investigating factors that influence algorithmic trustworthiness.
4. Developing ethical decision-support and decision-making systems.
5. Detecting, mitigating, or preventing biases in data and algorithms.
6. Ensuring the robust impartiality and inclusiveness of AI systems.

In terms of specific technical contributions addressing the program's goals, potential areas of focus may include:

1. Developing algorithms and representations that adapt quickly and appropriately to differences in training and test data across various population subgroups.
2. Establishing theoretical limitations on fairness, such as algorithmically proving the mutual inconsistency of certain fairness criteria.
3. Designing device interfaces that improve human interpretability of technologies and outcomes.
4. Incorporating socio-cultural considerations a priori into AI and ML advancements to enhance trustworthiness, accessibility, and utility.
5. Analyzing algorithmic design choices that impact fairness in speech, vision, and language applications.
6. Establishing metrics and methods for designing, piloting, and evaluating systems that mitigate adverse biases, including social bias, using human-machine collaboration and decision support.
7. Developing statistical methods for detecting bias in operational systems.

Our program promotes fundamental computer science research that surpasses current capabilities. The research must be transformative, embedding innovations into real systems, and incorporating robust evaluation plans. The lead principal investigator (PI) for each proposal must possess expertise in computer science. We encourage computationally focused research efforts that consider socio-technical and social behavioral needs. When considering such systems, proposers are encouraged to be ambitious in their scientific explorations, considering multiple contexts, and integrating disciplinary perspectives from social, behavioral, and cognitive sciences as needed and appropriate for the project's scope.
